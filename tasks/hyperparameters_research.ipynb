{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **pixel-level-segmentation-in-pets-unipr**\n",
    "\n",
    "@author Matteo Gianvenuti https://github.com/Mqtth3w \n",
    "@license GPL-3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model\n",
    "\n",
    "### Contents\n",
    "\n",
    "- Fixed hyperparameters and general information (UNet and DeepLabV3)\n",
    "- Find the best optimizer and loss (UNet and DeepLabV3)\n",
    "- Find the best dropout probability and batch size (UNet and DeepLabV3)\n",
    "- Find the best learning rate (UNet)\n",
    "- Find the best weight decay (UNeT)\n",
    "- Find the best learning rate (DeepLabV3)\n",
    "- Find the best weight decay (DeepLabV3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed hyperparameters and general information (UNet and DeepLabV3)\n",
    "\n",
    "- **epochs**: As maximun number of epochs I used 50 to train the model as musch as possible without exaggerating. Then to see how the training and test loss curves behave, surprisinly the best model configurations still had room of improvement also at 50 epochs. The average curves trend was bearish\n",
    "- **patience**: I used always six as patience for early stopping, this to have a balcend value, not too high but also not too little\n",
    "- **patience2**: This value tells the scheduler how many steps without improvement to wait before changing the learning rate to maximize the IoU. It should be lower than the previous, I used 5 to give the model some time to train\n",
    "- **momentum**: I used the standard choice 0.9\n",
    "\n",
    "I alwasy used **normalized data** because it leads to better results. Initially, I used a custom normalization with mean and std calculated on the dataset but the images were compressed in a very little range and it did not work so I passed to the mean and std for RGB images calucalted on ImagedNet.\n",
    "\n",
    "To improve the training and dfferentiate the data along the epochs I always used the **agumentations**: a random horizontal flip and a random color jitter added after the optimizer and loss function choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best optimizer and loss (UNet and DeepLabV3)\n",
    "\n",
    "I tested Adam because it is robust to the initial learning rate choice and because it is considered the state of the art. I also wanted to test RSMprop because a note implementation of UNet in PyTorch with good results use it. \n",
    "As loss function I tested:\n",
    "- The dice loss because it focuses on the overlap between the predicted and the ground truth mask. So I expect it to have the best IoU \n",
    "- The Cross-entropy loss because the elements in the mask can belong to three classes: the background, the pet edge and the pet\n",
    "- Their combination (loss1 + loss2)\n",
    "\n",
    "<br>\n",
    "\n",
    "| Model/run name | Optimizer | loss | IoU | L1 distance | \n",
    "|-------------|-------------|-------------|-------------|-------------|\n",
    "| **UNet_Adam_dice** | **Adam** | **Dice** | **0.8165** | **0.0704** |\n",
    "| UNet_Adam_CE | Adam | Cross-entropy | 0.8116 | 0.0722 |\n",
    "| UNet_Adam_combo | Adam | Dice + Cross-entropy | 0.8063 | 0.0748 |\n",
    "| UNet_RSMprop_dice | RSMprop | Dice | 0.8152 | 0.0709 |\n",
    "| UNet_RSMprop_CE | RSMprop | Cross-entropy | 0.8041 | 0.0753 |\n",
    "| UNet_RSMprop_combo | RSMprop | Dice + Cross-entropy | 0.7809 | 0.0857 |\n",
    "\n",
    "<br>\n",
    "\n",
    "As expected Adam optimizer and Dice loss are the best for this task. Then I used this configuration for both UNet and DeepLabV3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best dropout probability and batch size (UNet and DeepLabV3)\n",
    "\n",
    "After each hyperparameters research I used the one with highest score as default for the successive run. \n",
    "For the following test I also used 1e-6 as weight decay.\n",
    "\n",
    "<br>\n",
    "\n",
    "| Model/run name | Dropout p | Batch size | IoU | L1 distance | \n",
    "|-----------|-----------|-----------|-----------|-----------|\n",
    "| UNet_dr015_bs32_lr3e_4 | 0.15 | 32 | 0.8102 | 0.0731 |\n",
    "| **UNet_dr01_bs32_lr3e_4** | **0.1** | **32** | **0.8377** | **0.0615** |\n",
    "| UNet_dr015_bs16_lr2e_4 | 0.15 | 16 | 0.8376 | 0.0615 |\n",
    "| UNet_dr01_bs16_lr2e_4 | 0.1 | 16 | 0.8295 | 0.0648 |\n",
    "| UNet_dr015_bs8_lr1e_4 | 0.15 | 8 | 0.8181 | 0.0697 |\n",
    "| UNet_dr01_bs8_lr1e_4 | 0.1 | 8 | 0.8270 | 0.0659 |\n",
    "\n",
    "<br>\n",
    "\n",
    "As result the best dropout probability is 10% with 32 as batch size. For DeepLabV3 dropout is already defined and integrated inside the model structure.\n",
    "A higher batch size has less noisy gradient and hence more stable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best learning rate (UNet)\n",
    "\n",
    "<br>\n",
    "\n",
    "| Model/run name | Learning rate | IoU | L1 distance | \n",
    "|-----------|-----------|-----------|-----------|\n",
    "| UNet_lr1e_3 | 1e-3 | 0.8368 | 0.0618 |\n",
    "| UNet_lr2e_3 | 2e-3 | 0.6824 | 0.1322 |\n",
    "| UNet_lr5e_4 | 5e-4 | 0.8226 | 0.0679 |\n",
    "| UNet_lr7e_5 | 7e-5 | 0.8293 | 0.0649 |\n",
    "\n",
    "<br>\n",
    "\n",
    "The best configuration here did not outperform the one found previously with the learning rate 3e-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best weight decay (UNet)\n",
    "\n",
    "<br>\n",
    "\n",
    "| Model/run name | Weight decay | IoU | L1 distance | \n",
    "|-----------|-----------|-----------|-----------|\n",
    "| UNet_wd_1e_5 | 1e-5 | 0.8279 | 0.0655 |\n",
    "| **UNet_wd_1e_4** | **1e-4** | **0.8473** | **0.0574** |\n",
    "\n",
    "<br>\n",
    "\n",
    "Overall, the best UNet model is UNet_wd_1e_4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best learning rate (DeepLabV3)\n",
    "\n",
    "For the following test I used 1e-6 as weight decay.\n",
    "<br>\n",
    "\n",
    "| Model/run name | Learning rate | IoU | L1 distance | \n",
    "|-----------|-----------|-----------|-----------|\n",
    "| DeepLabV3ResNet_lr2e_4 | 2e-4 | 0.8911 | 0.0396 |\n",
    "| DeepLabV3ResNet_lr3e_4 | 3e-4 | 0.8910 | 0.0397 |\n",
    "| DeepLabV3ResNet_lr4e_4 | 4e-4 | 0.8926 | 0.0391 |\n",
    "| **DeepLabV3ResNet_lr5e_4** | **5e-4** | **0.8935** | **0.0387** |\n",
    "| DeepLabV3ResNet_lr7e_5 | 7e-5 | 0.8868 | 0.0412 | \n",
    "\n",
    "<br>\n",
    "So the best learning rate found for this net is 5e-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best weight decay (DeepLabV3)\n",
    "\n",
    "<br>\n",
    "\n",
    "| Model/run name | Weight decay | IoU | L1 distance | \n",
    "|-----------|-----------|-----------|-----------|\n",
    "| DeepLabV3ResNet_wd1e_5 | 1e-5 | | |\n",
    "| DeepLabV3ResNet_wd1e_4 | 1e-4 | | |\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 1996), started 0:00:22 ago. (Use '!kill 1996' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-271248f90169dd4e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-271248f90169dd4e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 13964), started 0:00:11 ago. (Use '!kill 13964' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c94c807d1083c9f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c94c807d1083c9f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for more details about the runs you can see the charts with tensorboard # http://localhost:6006\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir=../unet/runs \n",
    "%tensorboard --logdir=../deeplabv3_resnet101/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
